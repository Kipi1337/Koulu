{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Data sources\n",
    "- All files used in this exercise can be found under the Exercises/data_files directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Use gamedata.json for this task. This file contains information of games sold through Steam. Parse out the following information from the data (Important: Do not combine these filters, but do them separately!):\n",
    "- TOP 3 highest metacritic score. Present results using the following format: *Title* has metacritic score of *Score* (for example)\n",
    "- Games with price discount being 90 % or more. Present results using the following format: *Title* | Discount: *Savings* (for example Metal Gear Solid V: Ground Zeroes | Discount: 90.090090)\n",
    "- Games having metacritic score higher than steam score. Present results using the following format: *Title* has metacritic score of *MetacriticScore* and steam score of *SteamRatingPercent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 metacritic scores are:\n",
      "Star Wars: Knights of the Old Republic has metacritic score of 93\n",
      "Metal Gear Solid V: The Phantom Pain has metacritic score of 91\n",
      "Bayonetta has metacritic score of 90\n",
      " \n",
      "Discounts:\n",
      "Airscape: The Fall of Gravity | Savings: 4.5€ Discount:90.180361\n",
      "Making History: The Calm and the Storm | Savings: 4.5€ Discount:90.180361\n",
      "Phantaruk | Savings: 4.5€ Discount:90.180361\n",
      "Oozi Earth Adventure | Savings: 4.5€ Discount:90.180361\n",
      "House of Caravan | Savings: 4.5€ Discount:90.180361\n",
      "Avencast: Rise of the Mage | Savings: 9.0€ Discount:90.09009\n",
      "Teslagrad | Savings: 9.0€ Discount:90.09009\n",
      "Lucius | Savings: 9.0€ Discount:90.09009\n",
      "The Way | Savings: 13.5€ Discount:90.06004\n",
      "NEON STRUCT | Savings: 16.2€ Discount:90.050028\n",
      "Metal Gear Solid V: Ground Zeroes | Savings: 18.0€ Discount:90.045023\n",
      "White Wings  | Savings: 18.0€ Discount:90.045023\n",
      "The Long Journey Home | Savings: 18.0€ Discount:90.045023\n",
      "Shadow Tactics: Blades of the Shogun | Savings: 36.0€ Discount:90.022506\n",
      " \n",
      "Reviews\n",
      "Bionic Commando: Rearmed has metacritic score of 86 and a steam score of 71\n",
      "Commander 85 has metacritic score of 45 and a steam score of 35\n",
      "Full Spectrum Warrior has metacritic score of 80 and a steam score of 65\n",
      "Inversion has metacritic score of 59 and a steam score of 57\n",
      "Metal Gear Solid V: The Phantom Pain has metacritic score of 91 and a steam score of 90\n",
      "NBA 2K21 has metacritic score of 67 and a steam score of 39\n",
      "Port Royale 2 has metacritic score of 75 and a steam score of 68\n",
      "Project Cars 2 has metacritic score of 84 and a steam score of 79\n",
      "Star Wars: Knights of the Old Republic has metacritic score of 93 and a steam score of 90\n",
      "Starpoint Gemini Warlords has metacritic score of 73 and a steam score of 72\n",
      "The Long Journey Home has metacritic score of 68 and a steam score of 60\n",
      "Tidalis has metacritic score of 75 and a steam score of 70\n"
     ]
    }
   ],
   "source": [
    "# to avoid my own confusion and making the results more readable I have added empty prints and a \"category\" for each filter\n",
    "\n",
    "import json\n",
    "\n",
    "file_path = 'data_files/gamedata.json'\n",
    "\n",
    "with open(file_path) as gamedata:\n",
    "    games = json.load(gamedata)\n",
    "\n",
    "print(\"Top 3 metacritic scores are:\")\n",
    "\n",
    "top3 = sorted(games, key=lambda x: x['metacriticScore'], reverse=True)\n",
    "for game in top3[:3]:\n",
    "        title = game['title']\n",
    "        score = game['metacriticScore']\n",
    "        print(f\"{title} has metacritic score of {score}\")\n",
    "\n",
    "print(\" \")\n",
    "\n",
    "print(\"Discounts:\")\n",
    "\n",
    "discount = sorted(games, key=lambda x: x['savings'], reverse=True)\n",
    "for game in discount:\n",
    "    title = game['title']\n",
    "    discount = float(game['savings'])\n",
    "    original = float(game['normalPrice'])\n",
    "    new = float(game['salePrice'])\n",
    "    savings = original-new\n",
    "    if discount >= 90:\n",
    "        print(f\"{title} | Savings: {savings}€ Discount:{discount}\")\n",
    "        \n",
    "print(\" \")\n",
    "print(\"Reviews\")\n",
    "\n",
    "reviews = sorted(games, key=lambda x: x['title'])\n",
    "for game in reviews:\n",
    "    title = game['title']\n",
    "    metareview = game['metacriticScore']\n",
    "    steamreview = game['steamRatingPercent']\n",
    "    if metareview > steamreview:\n",
    "        print(f\"{title} has metacritic score of {metareview} and a steam score of {steamreview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "2 Use earthquakes.csv for this task. This file contains information about earthquakes recorded between 1965 and 2016. Earthquake magnitude value describes how strong the earthquake is. Magnitude information can be categorized like presented in the table below (*Source: http://www.geo.mtu.edu/UPSeis/magnitude.html*).\n",
    "\n",
    "| Magnitude       | Class | Effects |\n",
    "|-----------------|-------|---------|\n",
    "| 2.49 or less    | Minor | Usually not felt, but can be recorded by seismograph. |\n",
    "| 2.50 to 5.49    | Light | Often felt, but only causes minor damage. |\n",
    "| 5.50 to 6.09    | Moderate | Slight damage to buildings and other structures. |\n",
    "| 6.10 to 6.99    | Strong | May cause a lot of damage in very populated areas. |\n",
    "| 7.00 to 7.99    | Major | Major earthquake. Serious damage. |\n",
    "| 8.00 or greater | Great | Great earthquake. Can totally destroy communities near the epicenter. |\n",
    "\n",
    "Count how many earthquakes have occurred in each class.\n",
    "\n",
    "<b style=\"color:red;\">Notice:</b> The first value has been modified to be 2.4 or less compared to the original source (has been 2.5 or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 2.49 or less | Minor | Usually not felt, but can be recorded by seismograph. | 0 |\n",
      "| 2.50 to 5.49 | Light | Often felt, but only causes minor damage. | 0 |\n",
      "| 5.50 to 6.09 | Moderate | Slight damage to buildings and other structures. | 17639 |\n",
      "| 6.10 to 6.99 | Strong | May cause a lot of damage in very populated areas. | 5035 |\n",
      "| 7.00 to 7.99 | Major | Major earthquake. Serious damage. | 698 |\n",
      "| 8.00 or greater | Great | Great earthquake. Can totally destroy communities near the epicenter. | 40 |\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = 'data_files/earthquakes.csv'\n",
    "\n",
    "with open(file_path) as quake:\n",
    "    quakes = csv.reader(quake)\n",
    "    skip_firstRow = next(quakes, None)\n",
    "    \n",
    "    magnitude_classes = [\n",
    "        {\"range\": \"2.49 or less\", \"class\": \"Minor\", \"effects\": \"Usually not felt, but can be recorded by seismograph.\"},\n",
    "        {\"range\": \"2.50 to 5.49\", \"class\": \"Light\", \"effects\": \"Often felt, but only causes minor damage.\"},\n",
    "        {\"range\": \"5.50 to 6.09\", \"class\": \"Moderate\", \"effects\": \"Slight damage to buildings and other structures.\"},\n",
    "        {\"range\": \"6.10 to 6.99\", \"class\": \"Strong\", \"effects\": \"May cause a lot of damage in very populated areas.\"},\n",
    "        {\"range\": \"7.00 to 7.99\", \"class\": \"Major\", \"effects\": \"Major earthquake. Serious damage.\"},\n",
    "        {\"range\": \"8.00 or greater\", \"class\": \"Great\", \"effects\": \"Great earthquake. Can totally destroy communities near the epicenter.\"}\n",
    "    ]\n",
    "    \n",
    "    class_counts = {\n",
    "        \"Minor\": 0,\n",
    "        \"Light\": 0,\n",
    "        \"Moderate\": 0,\n",
    "        \"Strong\": 0,\n",
    "        \"Major\": 0,\n",
    "        \"Great\": 0\n",
    "    }\n",
    "    \n",
    "    for row in quakes:\n",
    "        magnitude = float(row[8])\n",
    "\n",
    "        if 0 <= magnitude < 2.49:\n",
    "            earthquake_class = \"Minor\"\n",
    "        elif 2.5 <= magnitude < 5.49:\n",
    "            earthquake_class = \"Light\"\n",
    "        elif 5.5 <= magnitude < 6.09:\n",
    "            earthquake_class = \"Moderate\"\n",
    "        elif 6.1 <= magnitude < 6.99:\n",
    "            earthquake_class = \"Strong\"\n",
    "        elif 7 <= magnitude < 7.99:\n",
    "            earthquake_class = \"Major\"\n",
    "        else:\n",
    "            earthquake_class = \"Great\"\n",
    "        class_counts[earthquake_class] += 1\n",
    "\n",
    "    for magnitude_class in magnitude_classes:\n",
    "        earthquake_class = magnitude_class['class']\n",
    "        effects = magnitude_class['effects']\n",
    "        count = class_counts[earthquake_class]\n",
    "\n",
    "#        print(f\"{earthquake_class} class {count} earthquakes:\")\n",
    "#        print(f\"Effects: {effects}\")\n",
    "#        print(\" \")\n",
    "\n",
    "for magnitude_class in magnitude_classes:\n",
    "    earthquake = magnitude_class['class']\n",
    "    magnitude = magnitude_class['range']\n",
    "    effects = magnitude_class['effects']\n",
    "    count = class_counts[earthquake]\n",
    "    print(f\"| {magnitude} | {earthquake} | {effects} | {count} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Use netflix_titles.xml for this task. This file contains information about Netflix movies and TV shows. **Important:** Movies have duration presented in minutes while TV shows have duration presented in amount of seasons! Parse out the following information from the data:\n",
    "- Movies released in 2017\n",
    "- TV show and movie amount (present both counts in separate lines)\n",
    "- Movies with a length between 15 and 20 minutes (values 15 and 20 included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies released in 2017: 744\n",
      "Number of movies: 5377\n",
      "Number of TV shows: 2410\n",
      "Number of movies with a duration between 15 and 20 minutes: 11\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "xml_file_path = 'data_files/netflix_titles.xml'\n",
    "\n",
    "# ET.parse is a module used to parse xml file, it turns element object to 'tree' representing xml document\n",
    "tree = ET.parse(xml_file_path)\n",
    "# getroot calls tree to obtain information from xml document and it gives ability to navigate and manipulate xml structure\n",
    "root = tree.getroot()\n",
    "\n",
    "movies_2017_count = 0\n",
    "for row_element in root.findall('row'):\n",
    "    show_type = row_element.find('type').text\n",
    "    release_year = int(row_element.find('release_year').text)\n",
    "    if release_year == 2017 and show_type == \"Movie\":\n",
    "        movies_2017_count += 1\n",
    "        \n",
    "moviescount = 0\n",
    "tvcount = 0\n",
    "\n",
    "for row_element in root.findall('row'):\n",
    "    show_type = row_element.find('type').text\n",
    "    if show_type == \"Movie\":\n",
    "        moviescount += 1\n",
    "    elif show_type == \"TV Show\":\n",
    "        tvcount += 1\n",
    "\n",
    "movies_15_to_20_minutes_count = 0\n",
    "\n",
    "for row_element in root.findall('row'):\n",
    "    show_type = row_element.find('type').text\n",
    "    duration_element = row_element.find('duration')\n",
    "    if duration_element is not None:\n",
    "        duration_text = duration_element.text\n",
    "        duration_numeric = int(duration_text.split(' ')[0])\n",
    "        if show_type == 'Movie' and 15 <= duration_numeric <= 20:\n",
    "            movies_15_to_20_minutes_count += 1\n",
    "\n",
    "            \n",
    "print(f\"Number of movies released in 2017: {movies_2017_count}\")\n",
    "print(f\"Number of movies: {moviescount}\")\n",
    "print(f\"Number of TV shows: {tvcount}\")\n",
    "print(f\"Number of movies with a duration between 15 and 20 minutes: {movies_15_to_20_minutes_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Use the following Rest API for this task: https://tie.digitraffic.fi/api/weather/v1/stations/data. Calculate the average for air temperature (ILMA) and humidity (ILMAN_KOSTEUS) values using two decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ILMA: -12.82\n",
      "Average ILMAN_KOSTEUS: 77.64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://tie.digitraffic.fi/api/weather/v1/stations/data\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# status code 200 is a successful request\n",
    "if response.status_code == 200:\n",
    "    # convert the json information to be readable by python\n",
    "    data = response.json()\n",
    "\n",
    "    # empty lists for variables\n",
    "    ilma_values = []\n",
    "    ilman_kosteus_values = []\n",
    "\n",
    "    # get station information\n",
    "    for station in data.get(\"stations\", []):\n",
    "        station_id = station.get(\"id\")\n",
    "\n",
    "        # get sensor values from stations\n",
    "        for sensor_value in station.get(\"sensorValues\", []):\n",
    "            sensor_name = sensor_value.get(\"name\")\n",
    "            value = sensor_value.get(\"value\")\n",
    "            unit = sensor_value.get(\"unit\")\n",
    "\n",
    "            # check sensor name\n",
    "            if sensor_name == 'ILMA':\n",
    "                ilma_values.append(value)\n",
    "            elif sensor_name == 'ILMAN_KOSTEUS':\n",
    "                ilman_kosteus_values.append(value)\n",
    "\n",
    "    # ilma avg\n",
    "    if ilma_values:\n",
    "        ilma_average = sum(ilma_values) / len(ilma_values)\n",
    "        print(f\"Average ILMA: {ilma_average:.2f}\")\n",
    "\n",
    "    # ilmankosteus avg\n",
    "    if ilman_kosteus_values:\n",
    "        ilman_kosteus_average = sum(ilman_kosteus_values) / len(ilman_kosteus_values)\n",
    "        print(f\"Average ILMAN_KOSTEUS: {ilman_kosteus_average:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
